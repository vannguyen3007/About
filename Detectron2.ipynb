{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Detectron2.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNS+j6ndkLKcqvIG2wzrKoX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vannguyen3007/About/blob/master/Detectron2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPwy85mufwTr"
      },
      "source": [
        "# install dependencies: (use cu101 because colab has CUDA 10.1)\n",
        "!pip install -U torch==1.5 torchvision==0.6 -f https://download.pytorch.org/whl/cu101/torch_stable.html \n",
        "!pip install cython pyyaml==5.1\n",
        "!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "!gcc --version\n",
        "# opencv is pre-installed on colab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_SYVS8UgU4F"
      },
      "source": [
        "# install detectron2:\n",
        "!pip install detectron2==0.1.3 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.5/index.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMk3rWiAhA9w"
      },
      "source": [
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog\n",
        "from detectron2.data.catalog import DatasetCatalog"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jNtfTB_hOTA"
      },
      "source": [
        "\n",
        "!pip install -q -U watermark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hizPSMlehw7H"
      },
      "source": [
        "import torch, torchvision\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "import glob\n",
        "\n",
        "import os\n",
        "import ntpath\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "import itertools\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import urllib\n",
        "import json\n",
        "import PIL.Image as Image\n",
        "\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor, DefaultTrainer\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.structures import BoxMode\n",
        "\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'\n",
        "\n",
        "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
        "\n",
        "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
        "\n",
        "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
        "\n",
        "rcParams['figure.figsize'] = 12, 8\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5j9p8tPh8-D"
      },
      "source": [
        "__Face Detection Data__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6-Gp-4Oh6Yy"
      },
      "source": [
        "!gdown --id 1K79wJgmPTWamqb04Op2GxW0SW9oxw8KS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLDSBHX4iArk"
      },
      "source": [
        "faces_df = pd.read_json('face_detection.json', lines=True)\n",
        "faces_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFdmz2xhiYMQ"
      },
      "source": [
        "__Data Preprocessing__\n",
        "\n",
        "The dataset contains only image URLs and annotations. We'll also normalize the annotations, so it's easier to use them with Detection_2 later on:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9b7soE3jiQyS"
      },
      "source": [
        "os.makedirs(\"faces\", exist_ok=True)\n",
        "\n",
        "dataset = []\n",
        "\n",
        "for index, row in tqdm(faces_df.iterrows(), total=faces_df.shape[0]):\n",
        "    img = urllib.request.urlopen(row[\"content\"])\n",
        "    img = Image.open(img)\n",
        "    img = img.convert('RGB')\n",
        "\n",
        "    image_name = f'face_{index}.jpeg'\n",
        "\n",
        "    img.save(f'faces/{image_name}', \"JPEG\")\n",
        "    \n",
        "    annotations = row['annotation']\n",
        "    for an in annotations:\n",
        "\n",
        "      data = {}\n",
        "\n",
        "      width = an['imageWidth']\n",
        "      height = an['imageHeight']\n",
        "      points = an['points']\n",
        "\n",
        "      data['file_name'] = image_name\n",
        "      data['width'] = width\n",
        "      data['height'] = height\n",
        "\n",
        "      data[\"x_min\"] = int(round(points[0][\"x\"] * width))\n",
        "      data[\"y_min\"] = int(round(points[0][\"y\"] * height))\n",
        "      data[\"x_max\"] = int(round(points[1][\"x\"] * width))\n",
        "      data[\"y_max\"] = int(round(points[1][\"y\"] * height))\n",
        "\n",
        "      data['class_name'] = 'face'\n",
        "      dataset.append(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMapQPq1jMFv"
      },
      "source": [
        "Let's put the data into a dataframe so that can have a better look:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMubS-2wjKMM"
      },
      "source": [
        "df = pd.DataFrame(dataset)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-G_SjWd-kIjh"
      },
      "source": [
        "print(df.file_name.unique().shape[0], df.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBvUgLLokMKt"
      },
      "source": [
        "We have a total 409 images (a lot less than the promised 500) and 1132 annotations. Let's save them to the disk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckvytDFmkK3D"
      },
      "source": [
        "\n",
        "df.to_csv('annotations.csv', header=True, index=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYzTKjLjkdOo"
      },
      "source": [
        "__Data Explodation__\n",
        "\n",
        "Let's see some sample annotated data. We'll use __OpenCV__ to load an image, add the bouding boxes, and resize it. That will define a helper function to do it all:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXQ0mIOLkbN5"
      },
      "source": [
        "def annotate_image(annotations, resize=True):\n",
        "  file_name = annotations.file_name.to_numpy()[0]\n",
        "  img = cv2.cvtColor(cv2.imread(f'faces/{file_name}'), cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  for i, a in annotations.iterrows():    \n",
        "    cv2.rectangle(img, (a.x_min, a.y_min), (a.x_max, a.y_max), (0, 255, 0), 2)\n",
        "\n",
        "  if not resize:\n",
        "    return img\n",
        "\n",
        "  return cv2.resize(img, (384, 384), interpolation = cv2.INTER_AREA)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dG4YeOv-k0ER"
      },
      "source": [
        "img_df = df[df.file_name == df.file_name.unique()[0]]\n",
        "img = annotate_image(img_df, resize = False)\n",
        "\n",
        "plt.imshow(img)\n",
        "plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCFP0LJ6lCOA"
      },
      "source": [
        "img_df = df[df.file_name == df.file_name.unique()[1]]\n",
        "img = annotate_image(img_df, resize=False)\n",
        "\n",
        "plt.imshow(img)\n",
        "plt.axis('off');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aV3oNd9lK8n"
      },
      "source": [
        "Those are good ones, the annotations are clearlt visible. This can use __torchvision__ to create a grid of images. Note that the images are various size, so we'll resize them:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91VMnTJBlInn"
      },
      "source": [
        "sample_images = [annotate_image(df[df.file_name == f])\n",
        "for f in df.file_name.unique()[:10]]\n",
        "sample_images = torch.as_tensor(sample_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ikNz1TLloR1"
      },
      "source": [
        "sample_images.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evgZyuZflrlz"
      },
      "source": [
        "sample_images = sample_images.permute(0, 3, 1, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBaESScylwX0"
      },
      "source": [
        "\n",
        "sample_images.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nNuyijKlyGu"
      },
      "source": [
        "plt.figure(figsize=(24, 12))\n",
        "grid_img = torchvision.utils.make_grid(sample_images, nrow=5)\n",
        "\n",
        "plt.imshow(grid_img.permute(1, 2, 0))\n",
        "plt.axis('off');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haaQJM-Kl06k"
      },
      "source": [
        "Need clearly see that some annotations are missing (column  4). That's real life data for you, sometimes you have to deal with it in some way."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "My2zKR3YmLRa"
      },
      "source": [
        "__Face Detection with Detectron 2__\n",
        "\n",
        "It is time to go through the steps of fine-tuning a model using a custom dataset. But first, let's save 5% of the data for testing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZV7i41pmJ2b"
      },
      "source": [
        "df = pd.read_csv('annotations.csv')\n",
        "\n",
        "IMAGES_PATH = f'faces'\n",
        "\n",
        "unique_files = df.file_name.unique()\n",
        "\n",
        "train_files = set(np.random.choice(unique_files, int(len(unique_files) * 0.95), replace=False))\n",
        "train_df = df[df.file_name.isin(train_files)]\n",
        "test_df = df[~df.file_name.isin(train_files)]\n",
        "\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ku-7eT2fmU-B"
      },
      "source": [
        "The classical train_test_split won't work here, cause we want a split amongst the file names.\n",
        "\n",
        "The next parts are written in a bit more generic way. Obviously, we have a single class - face. But adding more should be as simple as adding more annotations to the dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8b04bEHmR_k"
      },
      "source": [
        "classes = df.class_name.unique().tolist()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WBr9Hr7mYVR"
      },
      "source": [
        "\n",
        "Next, we'll write a function that converts our dataset into a format that is used by Detectron2:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7Bphg2SmWdG"
      },
      "source": [
        "def create_dataset_dicts(df, classes):\n",
        "  dataset_dicts = []\n",
        "  for image_id, img_name in enumerate(df.file_name.unique()):\n",
        "\n",
        "    record = {}\n",
        "\n",
        "    image_df = df[df.file_name == img_name]\n",
        "\n",
        "    file_path = f'{IMAGES_PATH}/{img_name}'\n",
        "    record[\"file_name\"] = file_path\n",
        "    record[\"image_id\"] = image_id\n",
        "    record[\"height\"] = int(image_df.iloc[0].height)\n",
        "    record[\"width\"] = int(image_df.iloc[0].width)\n",
        "\n",
        "    objs = []\n",
        "    for _, row in image_df.iterrows():\n",
        "\n",
        "      xmin = int(row.x_min)\n",
        "      ymin = int(row.y_min)\n",
        "      xmax = int(row.x_max)\n",
        "      ymax = int(row.y_max)\n",
        "\n",
        "      poly = [\n",
        "          (xmin, ymin), (xmax, ymin), \n",
        "          (xmax, ymax), (xmin, ymax)\n",
        "      ]\n",
        "      poly = list(itertools.chain.from_iterable(poly))\n",
        "\n",
        "      obj = {\n",
        "        \"bbox\": [xmin, ymin, xmax, ymax],\n",
        "        \"bbox_mode\": BoxMode.XYXY_ABS,\n",
        "        \"segmentation\": [poly],\n",
        "        \"category_id\": classes.index(row.class_name),\n",
        "        \"iscrowd\": 0\n",
        "        }\n",
        "      objs.append(obj)\n",
        "\n",
        "    record[\"annotations\"] = objs\n",
        "    dataset_dicts.append(record)\n",
        "  return dataset_dicts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wpo_Bh98mejv"
      },
      "source": [
        "We convert every annotation row to a single record with a list of annotations. You might also notice that we're building a polygon that is of the exact same shape as the bounding box. This is required for the image segmentation models in Detectron2.\n",
        "\n",
        "You'll have to register your dataset into the dataset and metadata catalogues:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCn2GYGtmb97"
      },
      "source": [
        "for d in [\"train\", \"val\"]:\n",
        "  DatasetCatalog.register(\"faces_\" + d, lambda d=d: create_dataset_dicts(train_df if d == \"train\" else test_df, classes))\n",
        "  MetadataCatalog.get(\"faces_\" + d).set(thing_classes=classes)\n",
        "\n",
        "statement_metadata = MetadataCatalog.get(\"faces_train\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1_79k_5mjUC"
      },
      "source": [
        "Unfortunately, evaluator for the test set is not included by default. We can easily fix that by writing our own trainer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPSVCYC3mg-O"
      },
      "source": [
        "class CocoTrainer(DefaultTrainer):\n",
        "  \n",
        "  @classmethod\n",
        "  def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
        "\n",
        "    if output_folder is None:\n",
        "        os.makedirs(\"coco_eval\", exist_ok=True)\n",
        "        output_folder = \"coco_eval\"\n",
        "\n",
        "    return COCOEvaluator(dataset_name, cfg, False, output_folder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyRFy997mo3q"
      },
      "source": [
        "Note issue:\n",
        "\n",
        "The evaluation results will be stored in the coco_eval folder if no folder is provided.\n",
        "\n",
        "Fine-tuning a Detectron2 model is nothing like writing PyTorch code. We'll load a configuration file, change a few values, and start the training process. But hey, it really helps if you know what you're doing 😂\n",
        "\n",
        "For this tutorial, we'll use the Mask R-CNN X101-FPN model. It is pre-trained on the __COCO dataset__ link  and achieves very good performance. The downside is that it is slow to train.\n",
        "\n",
        "Let's load the config file and the pre-trained model weights:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3HX599dmleO"
      },
      "source": [
        "cfg = get_cfg()\n",
        "\n",
        "cfg.merge_from_file(\n",
        "  model_zoo.get_config_file(\n",
        "    \"COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\"\n",
        "  )\n",
        ")\n",
        "\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\n",
        "  \"COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-pBydunmx0e"
      },
      "source": [
        "Specify the datasets (we registered those) we'll use for training and evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e88f1w6mv7l"
      },
      "source": [
        "cfg.DATASETS.TRAIN = (\"faces_train\",)\n",
        "cfg.DATASETS.TEST = (\"faces_val\",)\n",
        "cfg.DATALOADER.NUM_WORKERS = 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDBh4Tcpm1Ln"
      },
      "source": [
        "And for the optimizer, we'll do a bit of magic to converge to something nice:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RFoDtshmzcg"
      },
      "source": [
        "cfg.SOLVER.IMS_PER_BATCH = 4\n",
        "cfg.SOLVER.BASE_LR = 0.001\n",
        "cfg.SOLVER.WARMUP_ITERS = 1000\n",
        "cfg.SOLVER.MAX_ITER = 1500\n",
        "cfg.SOLVER.STEPS = (1000, 1500)\n",
        "cfg.SOLVER.GAMMA = 0.05"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9G8CniT0m4YF"
      },
      "source": [
        "Except for the standard stuff (batch size, max number of iterations, and learning rate) we have a couple of interesting params:\n",
        "\n",
        "* WARMUP_ITERS - the learning rate starts from 0 and goes to the preset one for this number of iterations\n",
        "\n",
        "* STEPS - the checkpoints (number of iterations) at which the learning rate will be reduced by GAMMA\n",
        "\n",
        "\n",
        "Finally, we'll specify the number of classes and the period at which we'll evaluate on the test set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8fA9RC1m2jR"
      },
      "source": [
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 64\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(classes)\n",
        "\n",
        "cfg.TEST.EVAL_PERIOD = 500"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lGMMtVEnBz2"
      },
      "source": [
        "Time to train, using our custom trainer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6mBYGL3m_sT"
      },
      "source": [
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "trainer = CocoTrainer(cfg) \n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dE5VL5xT-YNc"
      },
      "source": [
        "__Evaluating Object Detection Models__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAIVeXTjnDMR"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-Nv_QeX-gMF"
      },
      "source": [
        "%tensorboard --logdir output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vuFJTCW-iBW"
      },
      "source": [
        "!gdown --id 18Ev2bpdKsBaDufhVKf0cT6RmM3FjW3nL\n",
        "!mv face_detector.pth output/model_final.pth"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bX4Fhl0t-kIF"
      },
      "source": [
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.85\n",
        "predictor = DefaultPredictor(cfg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4kgcQPl-r9A"
      },
      "source": [
        "evaluator = COCOEvaluator(\"faces_val\", cfg, False, output_dir=\"./output/\")\n",
        "val_loader = build_detection_test_loader(cfg, \"faces_val\")\n",
        "inference_on_dataset(trainer.model, val_loader, evaluator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJMa8RbY-8uO"
      },
      "source": [
        "__Finding Faces in Images__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVu3XnfI-wWY"
      },
      "source": [
        "os.makedirs(\"annotated_results\", exist_ok=True)\n",
        "\n",
        "test_image_paths = test_df.file_name.unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQsVNKJb_FDr"
      },
      "source": [
        "for clothing_image in test_image_paths:\n",
        "  file_path = f'{IMAGES_PATH}/{clothing_image}'\n",
        "  im = cv2.imread(file_path)\n",
        "  outputs = predictor(im)\n",
        "  v = Visualizer(\n",
        "    im[:, :, ::-1],\n",
        "    metadata=statement_metadata, \n",
        "    scale=1., \n",
        "    instance_mode=ColorMode.IMAGE\n",
        "  )\n",
        "  instances = outputs[\"instances\"].to(\"cpu\")\n",
        "  instances.remove('pred_masks')\n",
        "  v = v.draw_instance_predictions(instances)\n",
        "  result = v.get_image()[:, :, ::-1]\n",
        "  file_name = ntpath.basename(clothing_image)\n",
        "  write_res = cv2.imwrite(f'annotated_results/{file_name}', result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clOPRTaK_HgS"
      },
      "source": [
        "annotated_images = [f'annotated_results/{f}' for f in test_df.file_name.unique()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xnPeRR1_L3P"
      },
      "source": [
        "img = cv2.cvtColor(cv2.imread(annotated_images[0]), cv2.COLOR_BGR2RGB)\n",
        "\n",
        "plt.imshow(img)\n",
        "plt.axis('off');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrLY94f3_Sgh"
      },
      "source": [
        "\n",
        "img = cv2.cvtColor(cv2.imread(annotated_images[1]), cv2.COLOR_BGR2RGB)\n",
        "\n",
        "plt.imshow(img)\n",
        "plt.axis('off');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRnjgbOy_VeY"
      },
      "source": [
        "img = cv2.cvtColor(cv2.imread(annotated_images[3]), cv2.COLOR_BGR2RGB)\n",
        "\n",
        "plt.imshow(img)\n",
        "plt.axis('off');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rDo-R_3_YgP"
      },
      "source": [
        "img = cv2.cvtColor(cv2.imread(annotated_images[4]), cv2.COLOR_BGR2RGB)\n",
        "\n",
        "plt.imshow(img)\n",
        "plt.axis('off');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAEWwukK_a5H"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}